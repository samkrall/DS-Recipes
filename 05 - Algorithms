#performance evaluation

#create lists for relevant model metrics, this will be used to compare different models
model = []
model_mean = []
model_std = []

#train/test/split
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=1) 

#k-fold cross validation
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
X = X
y = y

#folds, adjust based on # of data points
folds = 5
kfold = KFold(n_splits = folds, random_state = 1, shuffle=True)


#classification algorithms

#logistic regression
from sklearn.linear_model import  LogisticRegression 
method = LogisticRegression() 
results = cross_val_score(method, X, y, cv=kfold)

#adding to end of list of model metrics
model.append(method)
model_mean.append(round(results.mean(), 4))
model_std.append(round(results.std(), 4))

#decision tree classifier
from sklearn.tree import DecisionTreeClassifier
method = DecisionTreeClassifier() 
results = cross_val_score(method, X, y, cv=kfold)
model_mean.append(round(results.mean(), 4))
model_std.append(round(results.std(), 4))


#random forest classifier
from sklearn.ensemble import RandomForestClassifier
method = RandomForestClassifier() 
results = cross_val_score(method, X, y, cv=kfold)
model_mean.append(round(results.mean(), 4))
model_std.append(round(results.std(), 4))

#gradient boosting classifier
from sklearn.ensemble import GradientBoostingClassifier
method = GradientBoostingClassifier() 
results = cross_val_score(method, X, y, cv=kfold)
model_mean.append(round(results.mean(), 4))
model_std.append(round(results.std(), 4))

#XG Boost Classifier
method = XGBClassifier() 
results = cross_val_score(method, X, y, cv=kfold)
model_mean.append(round(results.mean(), 4))
model_std.append(round(results.std(), 4))

#logistic regression
from sklearn.linear_model import  LogisticRegression 
logreg = LogisticRegression() 
logreg.fit(X, y) 
logreg.predict(X)
logreg.score(X, y)

#Regression

#decision tree regressor
from sklearn.tree import DecisionTreeRegressor
DTR = DecisionTreeRegressor(random_state = 1)
DTR.fit(X, y)
predict(X)
score(X, y)

#Random Forest Regressor
from sklearn.ensemble import RandomForestRegressor
RFR = RandomForestRegressor(random_state = 1)
RFR.fit(X, y)
RFR.predict(X)
score(X, y)

models = pd.DataFrame({
    'Model' : model,
    'Score' : model_mean,
    'std' : model_std
})


models.sort_values(by = 'Score', ascending = False)

